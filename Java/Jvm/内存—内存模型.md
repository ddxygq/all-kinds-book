[toc]
## 内存模型
Java内存模型是在硬件内存模型上的更高层的抽象，它屏蔽了各种硬件和操作系统访问的差异性，保证了Java程序在各种平台下对内存的访问都能达到一致的效果

### 硬件背景
- 在现代计算机的硬件体系中，CPU的运算速度是非常快的，远远高于它从存储介质读取数据的速度，这里的存储介质有很多，比如磁盘、光盘、网卡、内存等，这些存储介质有一个很明显的特点——距离CPU越近的存储介质往往越小越贵越快，距离CPU越远的存储介质往往越大越便宜越慢
- 如果不想让CPU在那里白白等待，就必须想办法去把CPU的运算能力压榨出来，否则就会造成很大的浪费，而让CPU同时去处理多项任务则是最容易想到的，也是被证明非常有效的压榨手段，这也就是我们常说的“并发执行”
- 但是，让CPU并发地执行多项任务并不是那么容易实现的事，因为所有的运算都不可能只依靠CPU的计算就能完成，往往还需要跟内存进行交互，如读取运算数据、存储运算结果等。
- CPU与内存的交互往往是很慢的，所以这就要求我们要想办法在CPU和内存之间建立一种连接，使它们达到一种平衡，让运算能快速地进行，而这种连接就是我们常说的"高速缓存"
- 高速缓存的速度是非常接近CPU的，但是它的引入又带来了新的问题，现代的CPU往往是有多个核心的，每个核心都有自己的缓存，而多个核心之间是不存在时间片的竞争的，它们可以并行地执行，那么，怎么**保证这些缓存与主内存中的数据的一致性就成为了一个难题**。

### 解决方案

本身随着CPU和内存的发展速度差异的问题，导致CPU的速度远快于内存，所以现在的CPU加入了高速缓存，高速缓存一般可以分为L1、L2、L3三级缓存。

这导致了缓存一致性的问题，所以加入了缓存一致性协议，同时导致了内存可见性的问题，而编译器和CPU的重排序导致了原子性和有序性的问题，JMM内存模型正是对多线程操作下的一系列规范约束，因为不可能让程序员的代码去兼容所有的CPU

所以通过JMM我们才**屏蔽了不同硬件和操作系统内存的访问差异**，这样保证了Java程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程序能够正确执行。



![image-20201201083558597](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/2020/12/01/08:35:59-image-20201201083558597.png)



**原子性**：Java内存模型通过read、load、assign、use、store、write来保证原子性操作，此外还有lock和unlock，直接对应着synchronized关键字的monitorenter和monitorexit字节码指令。

**可见性**：可见性的问题在上面的回答已经说过，Java保证可见性可以认为通过volatile、synchronized、final来实现。

**有序性**：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证。



### 加载数据

- 加载到缓存中的数据也不是说用到哪个就加载哪个，而是加载内存中连续的数据，一般来说是加载连续的64个字节，因此，如果访问一个 long 类型的数组时，当数组中的一个值被加载到缓存中时，另外 7 个元素也会被加载到缓存中，这就是**缓存行**的概念

#### 缓存行
- 缓存是由缓存行组成的，通常是64字节（常用处理器的缓存行是64 字节的，比较旧的处理器缓存行是32字节），并且它有效地引用主内存中的一块地址。
- 但是，如果使用的数据结构中的项在内存中不是彼此相邻的，比如链表，那么将得不到免费缓存加载带来的好处。

![image-20201126105742302](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/2020/11/26/10:57:42-image-20201126105742302.png)
#### 缓存详解
![image-20201126105755840](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/2020/11/26/10:57:56-image-20201126105755840.png)
-  L1 缓存很小但很快，并且紧靠着在使用它的 CPU 内核。
-  L2 大一些，也慢一些，并且仍然只能被一个单独的 CPU 核使用
-  L3 在现代多核机器中更普遍，仍然更大，更慢，并且被单个插槽上的所有 CPU 核共享
-  主存保存着程序运行的所有数据，它更大，更慢，由全部插槽上的所有 CPU 核共享
-  当 CPU 执行运算的时候，它先去 L1 查找所需的数据，再去 L2，然后是 L3，最后如果这些缓存中都没有，所需的数据就要去主内存拿

#### 伪共享
- 设想如果我们有个long类型的变量a，它不是数组的一部分，而是一个单独的变量，并且还有另外一个 long 类型的变量 b 紧挨着它，那么当加载 a 的时候将免费加载 b。
- 看起来似乎没有什么毛病，但是如果一个 CPU 核心的线程在对 a 进行修改，另一个 CPU 核心的线程却在对 b 进行读取。
- 当前者修改 a 时，会把a和b同时加载到前者核心的缓存行中，更新完 a 后其它所有包含 a 的缓存行都将失效，因为其它缓存中的 a 不是最新值了。
- 而当后者读取 b时，发现这个缓存行已经失效了，需要从主内存中重新加载。

![image-20201126105808858](https://kingcall.oss-cn-hangzhou.aliyuncs.com/blog/img/2020/11/26/10:58:09-image-20201126105808858.png)

- 这样就出现了一个问题，b 和 a 完全不相干，每次却要因为 a 的更新需要从主内存重新读取，它被缓存未命中给拖慢了。

